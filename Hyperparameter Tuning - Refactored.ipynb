{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline \n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import model\n",
    "import model_utils\n",
    "import preprocessing_utils\n",
    "\n",
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "epochs = 500\n",
    "patience = 5\n",
    "\n",
    "num_timesteps_input = 7\n",
    "num_timesteps_output = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_trunc_dir = \"./data/raw/trunc/\"\n",
    "process_dir = \"./data/processed/\"\n",
    "\n",
    "preprocessing_utils.processed(raw_trunc_dir, process_dir, overwrite=False)\n",
    "A, X, metadata, cat2index, timestamps, means, stds = preprocessing_utils.load(process_dir)\n",
    "\n",
    "split_line1 = int(X.shape[2] * 0.6)\n",
    "split_line2 = int(X.shape[2] * 0.8)\n",
    "\n",
    "train_original_data = X[:, :, :split_line1]\n",
    "val_original_data = X[:, :, split_line1:split_line2]\n",
    "test_original_data = X[:, :, split_line2:]\n",
    "\n",
    "training_input, training_target = preprocessing_utils.generate_dataset(train_original_data,\n",
    "                                                   num_timesteps_input=num_timesteps_input,\n",
    "                                                   num_timesteps_output=num_timesteps_output)\n",
    "val_input, val_target = preprocessing_utils.generate_dataset(val_original_data,\n",
    "                                         num_timesteps_input=num_timesteps_input,\n",
    "                                         num_timesteps_output=num_timesteps_output)\n",
    "test_input, test_target = preprocessing_utils.generate_dataset(test_original_data,\n",
    "                                           num_timesteps_input=num_timesteps_input,\n",
    "                                           num_timesteps_output=num_timesteps_output)\n",
    "\n",
    "adj_mat = preprocessing_utils.get_normalized_adj(A)\n",
    "adj_mat = torch.from_numpy(adj_mat).float()\n",
    "\n",
    "adj_mat = adj_mat.to(device)\n",
    "training_input = training_input.to(device)\n",
    "training_target = training_target.to(device)\n",
    "val_input = val_input.to(device)\n",
    "val_target = val_target.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameter Optimization using Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_model(trial):\n",
    "    return model.Stgcn_Model(nodes_num = adj_mat.shape[0], \\\n",
    "                             features_num = training_input.shape[3], \\\n",
    "                             input_timesteps = num_timesteps_input, \\\n",
    "                             num_output = num_timesteps_output)\n",
    "\n",
    "def objective(trial):\n",
    "    stgcn = define_model(trial).to(device)\n",
    "    loss_criterion = nn.MSELoss()\n",
    "    \n",
    "    lr = trial.suggest_float(\"lr\", 1e-5, 1e-1, log=True)\n",
    "    optimizer_name = trial.suggest_categorical(\"optimizer\", [\"Adam\", \"RMSprop\", \"SGD\"])\n",
    "    optimizer = getattr(torch.optim, optimizer_name)(stgcn.parameters(), lr=lr)\n",
    "    batch_size = trial.suggest_categorical(\"bs\", [16, 32, 64])\n",
    "    \n",
    "    stgcn, training_loss, validation_loss = model_utils.train(stgcn, optimizer, lr, loss_criterion, epochs, patience, adj_mat,\n",
    "                  training_input, training_target, val_input, val_target, batch_size)\n",
    "    \n",
    "    return validation_loss[np.argmin(validation_loss)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study = optuna.create_study()\n",
    "\n",
    "study.optimize(objective, n_trials=30, timeout=3600)\n",
    "\n",
    "print(\"Best trial:\")\n",
    "trial = study.best_trial\n",
    "print(\"  Value: \", trial.value)\n",
    "print(\"  Params: \")\n",
    "for key, value in trial.params.items():\n",
    "    print(\"    {}: {}\".format(key, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_optimization_history(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_slice(study)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
