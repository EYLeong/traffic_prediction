{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline \n",
    "\n",
    "import math\n",
    "import copy\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import optim, nn\n",
    "\n",
    "import model\n",
    "import model_utils\n",
    "import preprocessing_utils\n",
    "\n",
    "from os.path import dirname, abspath\n",
    "import os\n",
    "import sys\n",
    "\n",
    "#to be put under model.py when I refactor\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x13fb8750a30>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cpu') # Heroku only have cpu\n",
    "\n",
    "epochs = 500\n",
    "batch_size = 32\n",
    "lr = 0.01\n",
    "patience = 10\n",
    "\n",
    "num_timesteps_input = 7 # Default is 30 minutes\n",
    "num_timesteps_output = 4 # Default is 10 minutes\n",
    "\n",
    "loss_criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\daryl\\\\Desktop\\\\SUTD school materials\\\\T7-TheoryAndPracticeOfDeepLearning\\\\Big Project\\\\traffic_prediction\\\\interactive-app'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing C:\\Users\\daryl\\Desktop\\SUTD school materials\\T7-TheoryAndPracticeOfDeepLearning\\Big Project\\traffic_prediction\\interactive-app\\data\\raw\\Thu_Apr_1_2021\\15_00_10.json\n",
      "Processing C:\\Users\\daryl\\Desktop\\SUTD school materials\\T7-TheoryAndPracticeOfDeepLearning\\Big Project\\traffic_prediction\\interactive-app\\data\\raw\\Thu_Apr_1_2021\\15_05_09.json\n",
      "Processing C:\\Users\\daryl\\Desktop\\SUTD school materials\\T7-TheoryAndPracticeOfDeepLearning\\Big Project\\traffic_prediction\\interactive-app\\data\\raw\\Thu_Apr_1_2021\\15_10_09.json\n",
      "Processing C:\\Users\\daryl\\Desktop\\SUTD school materials\\T7-TheoryAndPracticeOfDeepLearning\\Big Project\\traffic_prediction\\interactive-app\\data\\raw\\Thu_Apr_1_2021\\15_15_09.json\n",
      "Processing C:\\Users\\daryl\\Desktop\\SUTD school materials\\T7-TheoryAndPracticeOfDeepLearning\\Big Project\\traffic_prediction\\interactive-app\\data\\raw\\Thu_Apr_1_2021\\15_20_10.json\n",
      "Processing C:\\Users\\daryl\\Desktop\\SUTD school materials\\T7-TheoryAndPracticeOfDeepLearning\\Big Project\\traffic_prediction\\interactive-app\\data\\raw\\Thu_Apr_1_2021\\15_25_10.json\n",
      "Processing C:\\Users\\daryl\\Desktop\\SUTD school materials\\T7-TheoryAndPracticeOfDeepLearning\\Big Project\\traffic_prediction\\interactive-app\\data\\raw\\Thu_Apr_1_2021\\15_30_11.json\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "raw_dir = os.path.join(os.getcwd(), 'data', 'raw')\n",
    "process_dir = os.path.join(os.getcwd(), 'data', 'processed')\n",
    "\n",
    "# overwrite = False means that the processing function will only run if the process data files do not exist\n",
    "# overwrite = True => functions will run regardless\n",
    "preprocessing_utils.processed(raw_dir, process_dir, overwrite=True)\n",
    "A, X, metadata, cat2index, means, stds = preprocessing_utils.load(process_dir)\n",
    "\n",
    "\n",
    "test_original_data = X\n",
    "\n",
    "\n",
    "test_input, test_target = preprocessing_utils.generate_dataset(test_original_data,\n",
    "                                           num_timesteps_input=num_timesteps_input,\n",
    "                                           num_timesteps_output=num_timesteps_output)\n",
    "\n",
    "# input shape (num_samples ,num_vertices, num_timesteps_window, num_features)\n",
    "# output shape (num_samples ,num_vertices, num_timesteps_window)\n",
    "adj_mat = preprocessing_utils.get_normalized_adj(A)\n",
    "adj_mat = torch.from_numpy(adj_mat).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(53, 3, 7)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# indices = [(i, i + (num_timesteps_input + num_timesteps_output)) for i\n",
    "#                in range(X.shape[2] - (\n",
    "#                 num_timesteps_input + num_timesteps_output) + 1)]\n",
    "i = 0\n",
    "indices = [(i, i + (num_timesteps_input + num_timesteps_output))]\n",
    "\n",
    "# Save samples\n",
    "features, target = [], []\n",
    "for i, j in indices:\n",
    "    features.append(\n",
    "        X[:, :, i: i + num_timesteps_input].transpose(\n",
    "            (0, 2, 1)))\n",
    "    target.append(X[:, 0, i + num_timesteps_input: j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_input = torch.from_numpy(np.array(features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_target = torch.from_numpy(np.array(target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "saved_models_path = os.path.join(dirname(os.getcwd()), 'saved_models', 'last_saved_model.txt')\n",
    "with open(saved_models_path) as f:\n",
    "    saved_model = f.read()\n",
    "\n",
    "latest_model_path = os.path.join(dirname(os.getcwd()), saved_model)\n",
    "checkpoint = torch.load(latest_model_path, map_location=None)\n",
    "model_stgcn = model.Stgcn_Model(checkpoint['model_nodes_num'], checkpoint['model_features_num'], checkpoint['model_input_timesteps'], checkpoint['model_num_output'])\n",
    "model_stgcn.load_state_dict(checkpoint['state_dict'])\n",
    "optimizer = optim.Adam(model_stgcn.parameters(), lr=checkpoint['model_lr'])\n",
    "optimizer = optimizer.load_state_dict(checkpoint['opti_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = model_stgcn\n",
    "loaded_optimizer = optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 53, 7, 3])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 53, 0])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1234)\n",
    "\n",
    "\n",
    "predicted = model_utils.predict(loaded_model, test_input, adj_mat)\n",
    "predicted_denorm = preprocessing_utils.denormalize(predicted, stds[0], means[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.0907, -1.0230, -0.9304, -0.8908],\n",
       "         [ 0.3436,  0.2000,  0.1298,  0.0950],\n",
       "         [-0.6031, -0.4171, -0.2409, -0.0788],\n",
       "         [ 0.3337,  0.2361,  0.1865,  0.1483],\n",
       "         [ 0.9121,  0.9326,  0.9228,  0.9147],\n",
       "         [-0.4083, -0.5070, -0.5739, -0.5819],\n",
       "         [ 0.8408,  0.7398,  0.6884,  0.6627],\n",
       "         [-0.7209, -0.6660, -0.6274, -0.5984],\n",
       "         [ 0.7964,  0.8453,  0.8413,  0.8343],\n",
       "         [-0.6207, -0.6285, -0.6224, -0.6137],\n",
       "         [ 0.3557,  0.3293,  0.3090,  0.3042],\n",
       "         [-0.8883, -0.9533, -0.9888, -0.9856],\n",
       "         [-0.3670, -0.1425,  0.0149,  0.0708],\n",
       "         [ 0.7834,  0.6583,  0.5853,  0.5092],\n",
       "         [-0.1691, -0.2074, -0.2067, -0.2188],\n",
       "         [ 0.3602,  0.3151,  0.2924,  0.2676],\n",
       "         [-0.2834, -0.3301, -0.3577, -0.3538],\n",
       "         [-1.8811, -1.7838, -1.6867, -1.6231],\n",
       "         [-0.5618, -0.3278, -0.1591, -0.0832],\n",
       "         [ 0.2119,  0.3058,  0.3308,  0.3574],\n",
       "         [-0.2687, -0.3045, -0.3125, -0.2845],\n",
       "         [ 0.0735,  0.0037, -0.0417, -0.0433],\n",
       "         [-0.6682, -0.6169, -0.5986, -0.5712],\n",
       "         [-0.0468, -0.1238, -0.1822, -0.2167],\n",
       "         [ 0.5469,  0.4972,  0.4524,  0.4216],\n",
       "         [ 0.3450,  0.3435,  0.3366,  0.3393],\n",
       "         [ 0.8023,  0.6583,  0.5746,  0.5255],\n",
       "         [ 0.0855,  0.0194, -0.0301, -0.0295],\n",
       "         [ 0.0642,  0.0057, -0.0436, -0.0402],\n",
       "         [-0.0879, -0.1540, -0.1937, -0.1682],\n",
       "         [ 0.5942,  0.6459,  0.6240,  0.6058],\n",
       "         [ 0.8700,  0.8520,  0.8057,  0.7820],\n",
       "         [ 0.9036,  0.9610,  0.9435,  0.9436],\n",
       "         [-0.0944, -0.0811, -0.0769, -0.0692],\n",
       "         [ 0.0618,  0.1474,  0.1887,  0.2159],\n",
       "         [-0.5935, -0.5805, -0.5712, -0.5493],\n",
       "         [-0.4409, -0.4048, -0.3810, -0.3717],\n",
       "         [ 0.4893,  0.4571,  0.4099,  0.3744],\n",
       "         [ 0.1719,  0.0106, -0.0592, -0.0931],\n",
       "         [ 0.7650,  0.6576,  0.5988,  0.5786],\n",
       "         [-0.5625, -0.3968, -0.2669, -0.2211],\n",
       "         [-0.7379, -0.6510, -0.6344, -0.6302],\n",
       "         [-0.3878, -0.2306, -0.0984, -0.0505],\n",
       "         [-0.0552, -0.0657, -0.0755, -0.0930],\n",
       "         [ 0.0946,  0.0505,  0.0464,  0.0312],\n",
       "         [ 0.5357,  0.4883,  0.4935,  0.4961],\n",
       "         [-0.5957, -0.6682, -0.6999, -0.7178],\n",
       "         [-0.7617, -0.5767, -0.4587, -0.3938],\n",
       "         [-0.4999, -0.2479, -0.0399,  0.0318],\n",
       "         [-0.5213, -0.5221, -0.5270, -0.5425],\n",
       "         [-0.3220,  0.0514,  0.3193,  0.4060],\n",
       "         [-1.6902, -1.4080, -1.2292, -1.1336],\n",
       "         [-0.2771,  0.2220,  0.5438,  0.6560]]])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[2.7098, 2.7586, 2.8253, 2.8539],\n",
       "         [3.7436, 3.6401, 3.5895, 3.5644],\n",
       "         [3.0612, 3.1953, 3.3223, 3.4391],\n",
       "         [3.7365, 3.6661, 3.6304, 3.6029],\n",
       "         [4.1534, 4.1682, 4.1611, 4.1553],\n",
       "         [3.2017, 3.1305, 3.0823, 3.0765],\n",
       "         [4.1020, 4.0292, 3.9921, 3.9736],\n",
       "         [2.9764, 3.0159, 3.0438, 3.0646],\n",
       "         [4.0700, 4.1052, 4.1023, 4.0973],\n",
       "         [3.0485, 3.0430, 3.0474, 3.0536],\n",
       "         [3.7523, 3.7333, 3.7187, 3.7152],\n",
       "         [2.8557, 2.8088, 2.7832, 2.7856],\n",
       "         [3.2315, 3.3933, 3.5067, 3.5470],\n",
       "         [4.0606, 3.9705, 3.9178, 3.8630],\n",
       "         [3.3741, 3.3465, 3.3470, 3.3382],\n",
       "         [3.7556, 3.7231, 3.7067, 3.6888],\n",
       "         [3.2917, 3.2580, 3.2382, 3.2410],\n",
       "         [2.1401, 2.2103, 2.2802, 2.3261],\n",
       "         [3.0910, 3.2597, 3.3813, 3.4360],\n",
       "         [3.6487, 3.7163, 3.7344, 3.7536],\n",
       "         [3.3023, 3.2764, 3.2707, 3.2909],\n",
       "         [3.5489, 3.4986, 3.4659, 3.4647],\n",
       "         [3.0143, 3.0513, 3.0645, 3.0843],\n",
       "         [3.4622, 3.4067, 3.3647, 3.3398],\n",
       "         [3.8901, 3.8544, 3.8220, 3.7998],\n",
       "         [3.7446, 3.7436, 3.7386, 3.7405],\n",
       "         [4.0742, 3.9705, 3.9101, 3.8747],\n",
       "         [3.5576, 3.5099, 3.4743, 3.4747],\n",
       "         [3.5422, 3.5001, 3.4645, 3.4670],\n",
       "         [3.4326, 3.3850, 3.3563, 3.3747],\n",
       "         [3.9243, 3.9615, 3.9457, 3.9326],\n",
       "         [4.1230, 4.1100, 4.0767, 4.0596],\n",
       "         [4.1473, 4.1887, 4.1760, 4.1761],\n",
       "         [3.4279, 3.4375, 3.4406, 3.4461],\n",
       "         [3.5405, 3.6022, 3.6320, 3.6516],\n",
       "         [3.0682, 3.0775, 3.0843, 3.1000],\n",
       "         [3.1781, 3.2042, 3.2214, 3.2281],\n",
       "         [3.8486, 3.8254, 3.7914, 3.7658],\n",
       "         [3.6199, 3.5036, 3.4533, 3.4288],\n",
       "         [4.0473, 3.9699, 3.9276, 3.9130],\n",
       "         [3.0905, 3.2099, 3.3036, 3.3366],\n",
       "         [2.9641, 3.0268, 3.0387, 3.0417],\n",
       "         [3.2164, 3.3298, 3.4250, 3.4595],\n",
       "         [3.4562, 3.4486, 3.4415, 3.4290],\n",
       "         [3.5641, 3.5323, 3.5294, 3.5184],\n",
       "         [3.8821, 3.8479, 3.8517, 3.8536],\n",
       "         [3.0666, 3.0144, 2.9915, 2.9786],\n",
       "         [2.9469, 3.0803, 3.1654, 3.2121],\n",
       "         [3.1357, 3.3172, 3.4672, 3.5189],\n",
       "         [3.1202, 3.1197, 3.1161, 3.1050],\n",
       "         [3.2639, 3.5330, 3.7261, 3.7886],\n",
       "         [2.2777, 2.4811, 2.6100, 2.6789],\n",
       "         [3.2962, 3.6560, 3.8880, 3.9688]]])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_denorm"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
