{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline \n",
    "\n",
    "import math\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from utils import processed, load, denormalize, get_normalized_adj, generate_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Temporal_Layer(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel):\n",
    "        super(Temporal_Layer, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, (1, kernel))\n",
    "        self.conv2 = nn.Conv2d(in_channels, out_channels, (1, kernel))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.permute(0,3,1,2).type(torch.cuda.FloatTensor)\n",
    "        normal = self.conv1(x)\n",
    "        sig = torch.sigmoid(self.conv2(x))\n",
    "        out = normal * sig\n",
    "        out = out.permute(0,2,3,1)\n",
    "        # Convert back from NCHW to NHWC\n",
    "        return out\n",
    "        \n",
    "        \n",
    "class Stgcn_Block(nn.Module):\n",
    "    def __init__(self, in_channels, spatial_channels, out_channels, nodes_num):\n",
    "        super(Stgcn_Block, self).__init__()\n",
    "        self.temporal_layer1 = Temporal_Layer(in_channels, out_channels, kernel = 2) \n",
    "        self.temporal_layer2 = Temporal_Layer(in_channels = spatial_channels, out_channels = out_channels, kernel = 2)\n",
    "        \n",
    "        self.weight = nn.Parameter(torch.FloatTensor(out_channels, spatial_channels)) \n",
    "        self.initialise_weight()\n",
    "        \n",
    "        self.batch_norm = nn.BatchNorm2d(nodes_num)\n",
    "        \n",
    "        \n",
    "    def initialise_weight(self):\n",
    "        std_dv = 1. / math.sqrt(self.weight.shape[1])\n",
    "        self.weight.data.uniform_(-std_dv, std_dv)\n",
    "        \n",
    "    def forward(self, x, adj_hat):\n",
    "        # First temporal Block\n",
    "        temporal_block1 = self.temporal_layer1(x)\n",
    "        \n",
    "        #Spatial Graph Convolution\n",
    "        t = temporal_block1.permute(1,0,2,3) #Converts tensor from nhwc to hnwc for multiplication with adj_matrix\n",
    "        t = t.type(torch.cuda.DoubleTensor)\n",
    "        gconv1 = torch.einsum(\"ij, jklm -> kilm\", [adj_hat, t]) #(h,h) * (h,n,w,c) -> (n,h,w,c)\n",
    "        gconv2 = F.relu(torch.matmul(gconv1, self.weight.double()))\n",
    "        \n",
    "        #Second Temporal Block\n",
    "        temporal_block2 = self.temporal_layer2(gconv2) \n",
    "        \n",
    "        out = self.batch_norm(temporal_block2)\n",
    "        return out\n",
    "\n",
    "class Stgcn_Model(nn.Module):\n",
    "    def __init__(self, nodes_num, features_num, input_timesteps, num_output):\n",
    "        super(Stgcn_Model, self).__init__()\n",
    "        self.stgcn_block1 = Stgcn_Block(in_channels = features_num, spatial_channels = 16, out_channels = 64,\n",
    "                                       nodes_num = nodes_num)\n",
    "        \n",
    "        self.stgcn_block2 = Stgcn_Block(in_channels = 64, spatial_channels = 16,  out_channels = 64,\n",
    "                                       nodes_num = nodes_num)\n",
    "        \n",
    "        self.temporal_layer = Temporal_Layer(in_channels = 64, out_channels = 64, kernel = 2)\n",
    "        self.fc = nn.Linear((input_timesteps * 106) * 64, num_output)\n",
    "\n",
    "    def forward(self, adj_hat, x):\n",
    "        out1 = self.stgcn_block1(x, adj_hat)\n",
    "        out2 = self.stgcn_block2(out1, adj_hat)\n",
    "        out3 = self.temporal_layer(out2)\n",
    "        #out3_temp = out3.reshape((out3.shape[0], out3.shape[1], -1)) #reshaped to torch.Size([12, 53, 64])\n",
    "        out3_temp = out3.reshape(-1,40704)\n",
    "        out4 = self.fc(out3_temp) \n",
    "        return out4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(x_input, x_target, batch_size):\n",
    "    num_samples = x_input.shape[0]\n",
    "    shuffled_order = torch.randperm(num_samples)\n",
    "    \n",
    "    training_loss = []\n",
    "    for i in range(math.ceil(num_samples / batch_size)):\n",
    "        stgcn.train()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        start = i * batch_size\n",
    "        batch = shuffled_order[start:start+batch_size]\n",
    "        \n",
    "        #Drop left-overs\n",
    "        if len(batch) % batch_size != 0:\n",
    "            continue\n",
    "        \n",
    "        x_batch = x_input[batch].to(device = device)\n",
    "        y_batch = x_target[batch].to(device = device)\n",
    "        \n",
    "        \n",
    "        out = stgcn(adj_mat, x_batch)\n",
    "        loss = loss_criterion(out, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        training_loss.append(loss.detach().cpu().numpy())\n",
    "        \n",
    "    return sum(training_loss) / len(training_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "epochs = 50\n",
    "batch_size = 12\n",
    "\n",
    "num_timesteps_input = 6 # 30 minutes\n",
    "num_timesteps_output = 2 # 10 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_trunc_dir = \"./data/raw/trunc/\"\n",
    "process_dir = \"./data/processed/\"\n",
    "\n",
    "# overwrite = False means that the processing function will only run if the process data files do not exist\n",
    "# overwrite = True => functions will run regardless\n",
    "processed(raw_trunc_dir, process_dir, overwrite=False)\n",
    "A, X, metadata, means, stds = load(process_dir)\n",
    "\n",
    "split_line1 = int(X.shape[2] * 0.6)\n",
    "split_line2 = int(X.shape[2] * 0.8)\n",
    "\n",
    "train_original_data = X[:, :, :split_line1]\n",
    "val_original_data = X[:, :, split_line1:split_line2]\n",
    "test_original_data = X[:, :, split_line2:]\n",
    "\n",
    "training_input, training_target = generate_dataset(train_original_data,\n",
    "                                                   num_timesteps_input=num_timesteps_input,\n",
    "                                                   num_timesteps_output=num_timesteps_output)\n",
    "val_input, val_target = generate_dataset(val_original_data,\n",
    "                                         num_timesteps_input=num_timesteps_input,\n",
    "                                         num_timesteps_output=num_timesteps_output)\n",
    "test_input, test_target = generate_dataset(test_original_data,\n",
    "                                           num_timesteps_input=num_timesteps_input,\n",
    "                                           num_timesteps_output=num_timesteps_output)\n",
    "\n",
    "# input shape (num_samples ,num_vertices, num_timesteps_window, num_features)\n",
    "# output shape (num_samples ,num_vertices, num_timesteps_window)\n",
    "adj_mat = get_normalized_adj(A)\n",
    "adj_mat = torch.from_numpy(adj_mat).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(val_input, val_target, batch_size):\n",
    "    num_samples = val_input.shape[0]\n",
    "    shuffled_order = torch.randperm(num_samples)\n",
    "    total_val_loss = 0\n",
    "    counter = 0\n",
    "    for i in range(math.ceil(num_samples / batch_size)):\n",
    "        start = i * batch_size\n",
    "        batch = shuffled_order[start:start+batch_size]\n",
    "        \n",
    "        #Drop left-overs\n",
    "        if len(batch) % batch_size != 0:\n",
    "            continue\n",
    "        \n",
    "        val_input_batch = val_input[batch].to(device = device)\n",
    "        val_target_batch = val_target[batch].to(device = device)\n",
    "        out = stgcn(adj_mat, val_input_batch)\n",
    "        val_loss = loss_criterion(out, val_target_batch).to(device='cpu')\n",
    "        total_val_loss += val_loss\n",
    "        counter += 1\n",
    "        \n",
    "    total_val_loss = total_val_loss / counter\n",
    "    return total_val_loss\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(x_input):\n",
    "    num_samples = x_input.shape[0]\n",
    "    results = []\n",
    "    for i in range(math.ceil(num_samples/batch_size)):\n",
    "        start = i * batch_size\n",
    "        test_input = x_input[start: start+batch_size]\n",
    "        if test_input.shape[0] % batch_size != 0:\n",
    "            continue\n",
    "        with torch.no_grad():\n",
    "            stgcn.eval()\n",
    "            out = stgcn(adj_mat, test_input)\n",
    "            results.append(out)\n",
    "    return results\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 98.47137179731685\n",
      "Validation Loss: 2.1220011711120605\n",
      "Training Loss: 1.4746126346090898\n",
      "Validation Loss: 1.4187487363815308\n",
      "Training Loss: 1.3029539020941219\n",
      "Validation Loss: 1.1004555225372314\n",
      "Training Loss: 1.3849110598551397\n",
      "Validation Loss: 1.0937327146530151\n",
      "Training Loss: 1.3473029186062635\n",
      "Validation Loss: 1.1138156652450562\n",
      "Training Loss: 1.2626813229392557\n",
      "Validation Loss: 1.0558737516403198\n",
      "Training Loss: 1.1610293525425508\n",
      "Validation Loss: 1.1445482969284058\n",
      "Training Loss: 1.1049487656131785\n",
      "Validation Loss: 1.012089729309082\n",
      "Training Loss: 1.1337344864791727\n",
      "Validation Loss: 0.9852995872497559\n",
      "Training Loss: 1.1181226514558742\n",
      "Validation Loss: 1.0615489482879639\n",
      "Training Loss: 1.110053054151688\n",
      "Validation Loss: 0.9829967617988586\n",
      "Training Loss: 1.0861274845459883\n",
      "Validation Loss: 0.9814156293869019\n",
      "Training Loss: 1.0435187614219075\n",
      "Validation Loss: 0.9674597382545471\n",
      "Training Loss: 1.0548877370230016\n",
      "Validation Loss: 0.9961093664169312\n",
      "Training Loss: 1.0358485997041917\n",
      "Validation Loss: 0.9784520864486694\n",
      "Training Loss: 1.0288001941168372\n",
      "Validation Loss: 0.9648958444595337\n",
      "Training Loss: 1.0291471709223354\n",
      "Validation Loss: 0.9714862704277039\n",
      "Training Loss: 1.0271373725829915\n",
      "Validation Loss: 0.9671062231063843\n",
      "Training Loss: 1.0257860240451793\n",
      "Validation Loss: 0.9807520508766174\n",
      "Training Loss: 1.025528431894945\n",
      "Validation Loss: 0.9708653688430786\n",
      "Training Loss: 1.0265871095147363\n",
      "Validation Loss: 0.9991990923881531\n",
      "Training Loss: 1.0257074458395097\n",
      "Validation Loss: 0.9696610569953918\n",
      "Training Loss: 1.0261572752406891\n",
      "Validation Loss: 0.9695845246315002\n",
      "Training Loss: 1.0263370380682104\n",
      "Validation Loss: 0.9799456596374512\n",
      "Training Loss: 1.0247253437730717\n",
      "Validation Loss: 0.9585587978363037\n",
      "Training Loss: 1.0250890567340953\n",
      "Validation Loss: 0.9665642976760864\n",
      "Training Loss: 1.027643270033566\n",
      "Validation Loss: 0.9868313074111938\n",
      "Training Loss: 1.0314700375584995\n",
      "Validation Loss: 1.0058281421661377\n",
      "Training Loss: 1.03006236613753\n",
      "Validation Loss: 0.9940342903137207\n",
      "Training Loss: 1.0288033290980334\n",
      "Validation Loss: 0.9905333518981934\n",
      "Training Loss: 1.0294353966725702\n",
      "Validation Loss: 1.0038059949874878\n",
      "Training Loss: 1.02725464312788\n",
      "Validation Loss: 1.039830207824707\n",
      "Training Loss: 1.0259873830379649\n",
      "Validation Loss: 0.994003415107727\n",
      "Training Loss: 1.0250292933560947\n",
      "Validation Loss: 1.0134772062301636\n",
      "Training Loss: 1.0245096619753915\n",
      "Validation Loss: 0.9764119386672974\n",
      "Training Loss: 1.0289239057882584\n",
      "Validation Loss: 0.9860133528709412\n",
      "Training Loss: 1.0264432921129114\n",
      "Validation Loss: 0.9782956838607788\n",
      "Training Loss: 1.0275065403252361\n",
      "Validation Loss: 0.9952580332756042\n",
      "Training Loss: 1.0266684293746948\n",
      "Validation Loss: 1.0258710384368896\n",
      "Training Loss: 1.0271542631687327\n",
      "Validation Loss: 0.9827687740325928\n",
      "Training Loss: 1.0294175729713337\n",
      "Validation Loss: 0.9973052144050598\n",
      "Training Loss: 1.028432554102199\n",
      "Validation Loss: 0.9901811480522156\n",
      "Training Loss: 1.030715806280228\n",
      "Validation Loss: 0.9884132742881775\n",
      "Training Loss: 1.0312944825957804\n",
      "Validation Loss: 0.9890150427818298\n",
      "Training Loss: 1.0312881648221754\n",
      "Validation Loss: 1.001259446144104\n",
      "Training Loss: 1.0304896393243004\n",
      "Validation Loss: 0.9875296950340271\n",
      "Training Loss: 1.030954196172602\n",
      "Validation Loss: 0.9815972447395325\n",
      "Training Loss: 1.0316380004194332\n",
      "Validation Loss: 0.9876381158828735\n",
      "Training Loss: 1.031130675166686\n",
      "Validation Loss: 0.9910658001899719\n",
      "Training Loss: 1.0303672905911736\n",
      "Validation Loss: 0.9971969127655029\n"
     ]
    }
   ],
   "source": [
    "stgcn = Stgcn_Model(nodes_num = adj_mat.shape[0], features_num = training_input.shape[3],\n",
    "                    input_timesteps = num_timesteps_input, num_output = num_timesteps_output).to(device = device)\n",
    "\n",
    "optimizer = torch.optim.Adam(stgcn.parameters(), lr = 0.01)\n",
    "loss_criterion = nn.MSELoss()\n",
    "\n",
    "training_loss = []\n",
    "validation_loss = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    loss = train(training_input, training_target, batch_size)\n",
    "    training_loss.append(loss)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        stgcn.eval()\n",
    "        val_loss = validate(val_input, val_target, batch_size)\n",
    "        validation_loss.append(val_loss.item())\n",
    "\n",
    "    print(\"Training Loss: {}\".format(loss))\n",
    "    print(\"Validation Loss: {}\".format(val_loss))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "plt.plot(training_loss, label = 'Training Loss')\n",
    "plt.plot(validation_loss, label = 'Validation Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9389)\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    stgcn.eval()\n",
    "    test_loss = validate(test_input, test_target, batch_size)\n",
    "    print(test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = predict(test_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[tensor([[4.0647, 4.0624]], device='cuda:0')\n",
      "   tensor([[4.0647, 4.0624]], device='cuda:0')\n",
      "   tensor([[4.0649, 4.0625]], device='cuda:0')\n",
      "   tensor([[4.0648, 4.0624]], device='cuda:0')\n",
      "   tensor([[4.0650, 4.0626]], device='cuda:0')\n",
      "   tensor([[4.0650, 4.0625]], device='cuda:0')\n",
      "   tensor([[4.0653, 4.0628]], device='cuda:0')\n",
      "   tensor([[4.0648, 4.0623]], device='cuda:0')\n",
      "   tensor([[4.0644, 4.0625]], device='cuda:0')\n",
      "   tensor([[4.0640, 4.0624]], device='cuda:0')\n",
      "   tensor([[4.0647, 4.0622]], device='cuda:0')\n",
      "   tensor([[4.0650, 4.0627]], device='cuda:0')\n",
      "   tensor([[4.0647, 4.0623]], device='cuda:0')\n",
      "   tensor([[4.0649, 4.0625]], device='cuda:0')\n",
      "   tensor([[4.0646, 4.0622]], device='cuda:0')\n",
      "   tensor([[4.0648, 4.0624]], device='cuda:0')\n",
      "   tensor([[4.0647, 4.0623]], device='cuda:0')\n",
      "   tensor([[4.0647, 4.0623]], device='cuda:0')\n",
      "   tensor([[4.0647, 4.0624]], device='cuda:0')\n",
      "   tensor([[4.0646, 4.0623]], device='cuda:0')\n",
      "   tensor([[4.0645, 4.0622]], device='cuda:0')\n",
      "   tensor([[4.0648, 4.0624]], device='cuda:0')\n",
      "   tensor([[4.0648, 4.0624]], device='cuda:0')\n",
      "   tensor([[4.0647, 4.0623]], device='cuda:0')\n",
      "   tensor([[4.0647, 4.0623]], device='cuda:0')\n",
      "   tensor([[4.0647, 4.0623]], device='cuda:0')\n",
      "   tensor([[4.0650, 4.0626]], device='cuda:0')\n",
      "   tensor([[4.0649, 4.0625]], device='cuda:0')\n",
      "   tensor([[4.0649, 4.0624]], device='cuda:0')\n",
      "   tensor([[4.0651, 4.0627]], device='cuda:0')\n",
      "   tensor([[4.0650, 4.0627]], device='cuda:0')\n",
      "   tensor([[4.0647, 4.0623]], device='cuda:0')\n",
      "   tensor([[4.0648, 4.0624]], device='cuda:0')\n",
      "   tensor([[4.0649, 4.0626]], device='cuda:0')\n",
      "   tensor([[4.0652, 4.0630]], device='cuda:0')\n",
      "   tensor([[4.0649, 4.0625]], device='cuda:0')\n",
      "   tensor([[4.0648, 4.0624]], device='cuda:0')\n",
      "   tensor([[4.0646, 4.0622]], device='cuda:0')\n",
      "   tensor([[4.0646, 4.0623]], device='cuda:0')\n",
      "   tensor([[4.0648, 4.0624]], device='cuda:0')\n",
      "   tensor([[4.0646, 4.0622]], device='cuda:0')\n",
      "   tensor([[4.0647, 4.0623]], device='cuda:0')\n",
      "   tensor([[4.0645, 4.0621]], device='cuda:0')\n",
      "   tensor([[4.0646, 4.0624]], device='cuda:0')\n",
      "   tensor([[4.0650, 4.0626]], device='cuda:0')\n",
      "   tensor([[4.0646, 4.0623]], device='cuda:0')\n",
      "   tensor([[4.0653, 4.0629]], device='cuda:0')\n",
      "   tensor([[4.0647, 4.0623]], device='cuda:0')\n",
      "   tensor([[4.0646, 4.0623]], device='cuda:0')\n",
      "   tensor([[4.0648, 4.0624]], device='cuda:0')\n",
      "   tensor([[4.0648, 4.0624]], device='cuda:0')\n",
      "   tensor([[4.0648, 4.0624]], device='cuda:0')\n",
      "   tensor([[4.0650, 4.0625]], device='cuda:0')\n",
      "   tensor([[4.0652, 4.0628]], device='cuda:0')\n",
      "   tensor([[4.0649, 4.0624]], device='cuda:0')\n",
      "   tensor([[4.0649, 4.0624]], device='cuda:0')\n",
      "   tensor([[4.0650, 4.0626]], device='cuda:0')\n",
      "   tensor([[4.0667, 4.0641]], device='cuda:0')\n",
      "   tensor([[4.0642, 4.0619]], device='cuda:0')\n",
      "   tensor([[4.0651, 4.0626]], device='cuda:0')\n",
      "   tensor([[4.0648, 4.0624]], device='cuda:0')\n",
      "   tensor([[4.0647, 4.0623]], device='cuda:0')\n",
      "   tensor([[4.0646, 4.0622]], device='cuda:0')\n",
      "   tensor([[4.0647, 4.0623]], device='cuda:0')\n",
      "   tensor([[4.0647, 4.0623]], device='cuda:0')\n",
      "   tensor([[4.0646, 4.0622]], device='cuda:0')\n",
      "   tensor([[4.0646, 4.0623]], device='cuda:0')\n",
      "   tensor([[4.0647, 4.0623]], device='cuda:0')\n",
      "   tensor([[4.0647, 4.0624]], device='cuda:0')\n",
      "   tensor([[4.0647, 4.0623]], device='cuda:0')\n",
      "   tensor([[4.0647, 4.0624]], device='cuda:0')\n",
      "   tensor([[4.0645, 4.0620]], device='cuda:0')\n",
      "   tensor([[4.0647, 4.0623]], device='cuda:0')\n",
      "   tensor([[4.0646, 4.0623]], device='cuda:0')\n",
      "   tensor([[4.0647, 4.0623]], device='cuda:0')\n",
      "   tensor([[4.0648, 4.0624]], device='cuda:0')\n",
      "   tensor([[4.0648, 4.0624]], device='cuda:0')\n",
      "   tensor([[4.0649, 4.0625]], device='cuda:0')\n",
      "   tensor([[4.0649, 4.0625]], device='cuda:0')\n",
      "   tensor([[4.0651, 4.0627]], device='cuda:0')\n",
      "   tensor([[4.0650, 4.0624]], device='cuda:0')\n",
      "   tensor([[4.0650, 4.0625]], device='cuda:0')\n",
      "   tensor([[4.0650, 4.0626]], device='cuda:0')\n",
      "   tensor([[4.0646, 4.0622]], device='cuda:0')\n",
      "   tensor([[4.0646, 4.0622]], device='cuda:0')\n",
      "   tensor([[4.0650, 4.0627]], device='cuda:0')\n",
      "   tensor([[4.0646, 4.0622]], device='cuda:0')\n",
      "   tensor([[4.0647, 4.0623]], device='cuda:0')\n",
      "   tensor([[4.0647, 4.0624]], device='cuda:0')\n",
      "   tensor([[4.0647, 4.0623]], device='cuda:0')\n",
      "   tensor([[4.0648, 4.0625]], device='cuda:0')\n",
      "   tensor([[4.0646, 4.0622]], device='cuda:0')\n",
      "   tensor([[4.0647, 4.0624]], device='cuda:0')\n",
      "   tensor([[4.0648, 4.0625]], device='cuda:0')\n",
      "   tensor([[4.0648, 4.0624]], device='cuda:0')\n",
      "   tensor([[4.0646, 4.0623]], device='cuda:0')\n",
      "   tensor([[4.0646, 4.0622]], device='cuda:0')\n",
      "   tensor([[4.0648, 4.0625]], device='cuda:0')\n",
      "   tensor([[4.0648, 4.0624]], device='cuda:0')\n",
      "   tensor([[4.0647, 4.0623]], device='cuda:0')\n",
      "   tensor([[4.0649, 4.0624]], device='cuda:0')\n",
      "   tensor([[4.0650, 4.0626]], device='cuda:0')\n",
      "   tensor([[4.0647, 4.0623]], device='cuda:0')\n",
      "   tensor([[4.0651, 4.0626]], device='cuda:0')\n",
      "   tensor([[4.0652, 4.0629]], device='cuda:0')\n",
      "   tensor([[4.0648, 4.0624]], device='cuda:0')\n",
      "   tensor([[4.0647, 4.0626]], device='cuda:0')\n",
      "   tensor([[4.0649, 4.0626]], device='cuda:0')\n",
      "   tensor([[4.0650, 4.0626]], device='cuda:0')\n",
      "   tensor([[4.0644, 4.0621]], device='cuda:0')\n",
      "   tensor([[4.0648, 4.0624]], device='cuda:0')\n",
      "   tensor([[4.0646, 4.0622]], device='cuda:0')\n",
      "   tensor([[4.0647, 4.0624]], device='cuda:0')\n",
      "   tensor([[4.0648, 4.0625]], device='cuda:0')\n",
      "   tensor([[4.0645, 4.0620]], device='cuda:0')\n",
      "   tensor([[4.0650, 4.0626]], device='cuda:0')\n",
      "   tensor([[4.0645, 4.0622]], device='cuda:0')\n",
      "   tensor([[4.0647, 4.0623]], device='cuda:0')\n",
      "   tensor([[4.0646, 4.0622]], device='cuda:0')\n",
      "   tensor([[4.0646, 4.0623]], device='cuda:0')\n",
      "   tensor([[4.0647, 4.0623]], device='cuda:0')\n",
      "   tensor([[4.0646, 4.0623]], device='cuda:0')\n",
      "   tensor([[4.0648, 4.0624]], device='cuda:0')\n",
      "   tensor([[4.0648, 4.0624]], device='cuda:0')]]]\n"
     ]
    }
   ],
   "source": [
    "print(denormalize(results, stds[0], means[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[3., 3.],\n",
      "         [3., 3.],\n",
      "         [4., 4.],\n",
      "         ...,\n",
      "         [5., 5.],\n",
      "         [3., 3.],\n",
      "         [5., 5.]],\n",
      "\n",
      "        [[3., 3.],\n",
      "         [3., 3.],\n",
      "         [4., 4.],\n",
      "         ...,\n",
      "         [5., 5.],\n",
      "         [3., 3.],\n",
      "         [5., 5.]],\n",
      "\n",
      "        [[3., 3.],\n",
      "         [3., 3.],\n",
      "         [4., 4.],\n",
      "         ...,\n",
      "         [5., 4.],\n",
      "         [3., 3.],\n",
      "         [5., 4.]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[4., 3.],\n",
      "         [4., 4.],\n",
      "         [5., 5.],\n",
      "         ...,\n",
      "         [5., 5.],\n",
      "         [4., 4.],\n",
      "         [6., 5.]],\n",
      "\n",
      "        [[3., 4.],\n",
      "         [4., 4.],\n",
      "         [5., 5.],\n",
      "         ...,\n",
      "         [5., 4.],\n",
      "         [4., 4.],\n",
      "         [5., 4.]],\n",
      "\n",
      "        [[4., 4.],\n",
      "         [4., 4.],\n",
      "         [5., 5.],\n",
      "         ...,\n",
      "         [4., 3.],\n",
      "         [4., 3.],\n",
      "         [4., 4.]]])\n"
     ]
    }
   ],
   "source": [
    "print(denormalize(test_target, stds[0], means[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
