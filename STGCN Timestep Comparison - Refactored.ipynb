{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline \n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import model\n",
    "import model_utils\n",
    "import preprocessing_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "epochs = 500\n",
    "batch_size = 16\n",
    "lr = 0.0005920310461116504\n",
    "patience = 10\n",
    "\n",
    "num_timesteps_inputs = [6,7,8,9,10,11]\n",
    "num_timesteps_outputs = [2,3,4,5,6]\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_rmse(pred, actual, stds, means, loss_criterion):\n",
    "    denorm_pred = preprocessing_utils.denormalize(pred, stds[0], means[0])\n",
    "    denorm_actual = preprocessing_utils.denormalize(actual, stds[0], means[0])\n",
    "    mse_loss = loss_criterion(denorm_pred, denorm_actual)\n",
    "    rmse_loss = mse_loss.sqrt()\n",
    "    return rmse_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_trunc_dir = \"./data/raw/trunc/\"\n",
    "process_dir = \"./data/processed/\"\n",
    "\n",
    "preprocessing_utils.processed(raw_trunc_dir, process_dir, overwrite=False)\n",
    "A, X, metadata, cat2index, timestamps, means, stds = preprocessing_utils.load(process_dir)\n",
    "\n",
    "split_line1 = int(X.shape[2] * 0.6)\n",
    "split_line2 = int(X.shape[2] * 0.8)\n",
    "\n",
    "train_original_data = X[:, :, :split_line1]\n",
    "val_original_data = X[:, :, split_line1:split_line2]\n",
    "test_original_data = X[:, :, split_line2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for num_timesteps_input in num_timesteps_inputs:\n",
    "    for num_timesteps_output in num_timesteps_outputs:\n",
    "        print(f\"Input Timesteps: {num_timesteps_input}, Output Timesteps: {num_timesteps_output}\")\n",
    "        \n",
    "        #Getting the Data\n",
    "        training_input, training_target = preprocessing_utils.generate_dataset(train_original_data,\n",
    "                                                   num_timesteps_input=num_timesteps_input,\n",
    "                                                           num_timesteps_output=num_timesteps_output)\n",
    "        val_input, val_target = preprocessing_utils.generate_dataset(val_original_data,\n",
    "                                                 num_timesteps_input=num_timesteps_input,\n",
    "                                                 num_timesteps_output=num_timesteps_output)\n",
    "        test_input, test_target = preprocessing_utils.generate_dataset(test_original_data,\n",
    "                                                   num_timesteps_input=num_timesteps_input,\n",
    "                                                   num_timesteps_output=num_timesteps_output)\n",
    "\n",
    "        adj_mat = preprocessing_utils.get_normalized_adj(A)\n",
    "        adj_mat = torch.from_numpy(adj_mat).float()\n",
    "        \n",
    "        #Init model\n",
    "        stgcn = model.Stgcn_Model(nodes_num = adj_mat.shape[0], features_num = training_input.shape[3],\n",
    "                                  input_timesteps = num_timesteps_input, num_output = num_timesteps_output)\n",
    "\n",
    "        optimizer = torch.optim.Adam(stgcn.parameters(), lr = lr)\n",
    "        loss_criterion = nn.MSELoss()\n",
    "        \n",
    "        #Train\n",
    "        stgcn.to(device)\n",
    "        adj_mat = adj_mat.to(device)\n",
    "        training_input = training_input.to(device)\n",
    "        training_target = training_target.to(device)\n",
    "        val_input = val_input.to(device)\n",
    "        val_target = val_target.to(device)\n",
    "\n",
    "        stgcn, training_loss, validation_loss = model_utils.train(stgcn, optimizer, lr,\n",
    "                loss_criterion, epochs, patience, adj_mat, training_input, training_target, val_input, val_target, batch_size)\n",
    "\n",
    "        \n",
    "        #Plot loss\n",
    "        plt.plot(training_loss, label = 'Training Loss')\n",
    "        plt.plot(validation_loss, label = 'Validation Loss')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "        \n",
    "        torch.manual_seed(1234)\n",
    "\n",
    "        test_input = test_input.to(device)\n",
    "        test_target = test_target.to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            results = model_utils.predict(stgcn, test_input, adj_mat)\n",
    "            normalized_test_loss = model_utils.validate(stgcn, loss_criterion, test_input, test_target, adj_mat, batch_size)\n",
    "            print(\"Normalized_test_loss: {}\".format(normalized_test_loss))\n",
    "            denormalized_rmse_loss = get_test_rmse(results.cpu(), test_target.cpu(), stds, means, loss_criterion).item()\n",
    "            print(\"Denormalized_test_loss: {}\".format(denormalized_rmse_loss))\n",
    "            \n",
    "        path = model_utils.save_model_timesteps(stgcn,optimizer,num_timesteps_input,\n",
    "                                        num_timesteps_output, denormalized_rmse_loss)\n",
    "        print('Saved model to {}\\n\\n'.format(path))\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
